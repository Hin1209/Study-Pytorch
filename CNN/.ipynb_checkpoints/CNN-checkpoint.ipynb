{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "21bVfYpEg4Bk"
   },
   "source": [
    "# 합성곱 연산  \n",
    "우리가 책을 읽을때 왼쪽 위부터 오른쪽 아래를 순서로 읽어가는 것처럼, 특정 범위의 데이터에 필터를 곱해 필터 입력 하나당 입력 이미지 전체에 대한 필터의 일치 정도를 뽑아내는 것을 말한다.  \n",
    "여기서 필터의 크기나 필터가 이동하는 단위는 자유롭게 설정이 가능하다. 필터의 이동 단위는 stride라고 한다.  \n",
    "이미지에 대해 필터를 곱해 나오게 되는 출력값을 __활성화 지도(activation map)__ 또는 __특성 지도(feature map)__라고 한다.   \n",
    "\n",
    "이 과정을 통해 나온 활성화 지도의 크기는 $$ O = floor(\\frac{I - K}{S} + 1)$$ 이다.  \n",
    "여기서 floor는 버림 함수이다. \n",
    "합성곱 연산도 입력과 가중치의 조합으로 이루어진 연산이므로 비선형성을 추가하기 위해서 활성화 함수가 필요하다. 보통 ReLU 함수를 많이 쓴다.  \n",
    "## ReLU  \n",
    "ReLU 함수는 0 이하의 값이 들어오면 활성화 값을 0으로 맞추고, 0보다 큰 값이 들어오면 그대로 전달하는 함수이다.  \n",
    "이 경우 역전파되는 값들의 기울기도 $y = x$를 미분해 1이 나오기 때문에 기울기 값이 그대로 전파되어 학습 속도가 빠르다는 장점이 있다.  \n",
    "반면 어느 순간 큰 손실이 발생해 weight과 bias가 마이너스로 떨어지는 경우 어떠한 입력값에도 0을 전달해버리는 Dying Neuron 현상이 발생하기도 한다.  \n",
    "이런 현상을 해결하기 위해 나온 ReLU가 변형된 형태로 leaky ReLU와 randomized leaky ReLU가 있다.  \n",
    "leaky ReLU는 수식을 $f(x) = max(ax, x)$ 로 변형시키고 상수 a에 작은 값을 설정해 입력이 0보다 작을때는 가중치가 양의 방향으로, 0보다 클 때는 가중치가 음의 방향으로 업데이트 되게끔 한다. randomized leaky ReLU는 a 값을 임의로 설정하는 함수이다.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XG0Z1fFNt4Kx"
   },
   "source": [
    "# 패딩과 풀링  \n",
    "합성곱 신경망에서는 레이어를 하나씩 통과할때 마다 입력의 크기가 점점 작아지게 된다. 이러한 경우에 원래 크기가 작았던 입력에 대해서는 쓸 수 있는 레이어의 수가 제한이 되어버리므로, __패딩(padding)__을 통해서 입력값의 크기 손실을 방지한다.  \n",
    "패딩이란 입력값을 새로운 패딩값으로 둘러싸는 것을 의미한다. 1 패딩을 주면 입력 이미지를 한바퀴 둘러싸기 때문에 크기는 2씩 늘어나게 된다.  \n",
    "이러한 경우 활성화 지도의 크기는 다음과 같다. $$O = floor(\\frac{I - K + 2P}{S} + 1)$$ \n",
    " \n",
    "패딩과 반대의 경우로, 입력값의 크기가 너무 커 학습이 오래 걸리는 반면에, 엄청나게 높은 화질이 필요하지 않거나 넓은 특징을 파악해야 하는 경우에 __풀링(pooling)__을 사용한다.  \n",
    "풀링은 다운샘플링 또는 서브샘플링의 일종으로, 합성곱 신경망에서는 크게 두 가지가 사용된다.  \n",
    "1. Max pooling  \n",
    "일정 크기의 구간 내에서 가장 큰 값만 전달하고 다른 정보는 버리는 방법. 일정 구간에서 해당 필터의 모양과 가장 비슷한 부분을 전달하는 연산이다.  \n",
    "2. Average pooling  \n",
    "일정 크기의 구간 내의 값들의 평균을 전달하는 방법. 해당 필터의 모양과 평균적으로 얼마나 일치하는지를 뽑아낸다.  \n",
    "    \n",
    "# 모델의 3차원적 이해  \n",
    "입력 이미지를 컬러 이미지라고 가정하면, 컬러 이미지는 각 픽셀마다 RGB 값을 가지므로 총 3개의 채널이 존재한다. 따라서 입력의 크기는 가로x세로x3 이 된다. 여기에 3x3 필터를 적용하면 3x3x3 필터를 적용하는 것과 같다.  \n",
    "이 이미지에 스트라이드를 1, 패딩을 1, 채널은 16으로 설정하고 필터를 적용하면 가로와 세로의 길이는 변하지 않고 채널만 16개로 늘어난 결과가 나오게된다.  \n",
    "합성곱 연산을 하고 나면 활성화 함수 ReLU를 통과한다. 여기서 활성화 함수를 적용하기 전에 먼저 풀링을 하고 간다.  \n",
    "2x2 커널을 적용하고 스트라이드를 2를 주면 가로 세로 크기가 절반으로 줄어들게 된다.  \n",
    "특성들을 충분히 뽑아냈다고 판단되면 완전연결 레이어(fully connected layer)를 적용한다.  \n",
    "가로x세로x채널 이었던 텐서를 쭉 펴면 가로x세로x채널의 길이를 가지는 벡터가 생성되는데, 이 벡터를 인수로 받는 인공신경망을 만들어서 원하는 결과를 도출해낸다.  \n",
    "\n",
    "# 소프트맥스 함수  \n",
    "인공 신경망의 결과는 특정 수치값으로 나오는데, 이를 정답과 비교하기 위해 소프트맥스 함수를 사용한다.  \n",
    "우선 정답을 구분하려는 클래스의 개수에 맞게 바꾼다.  \n",
    "예를 들어 클래스의 개수가 2개이고, 강아지, 고양이 순으로 결과값이 도출된다면 고양이라는 정답은 [0, 1]의 벡터로, 강아지는 [1, 0]으로 변환시켜 개수를 맞춘다.  \n",
    "이렇게 하나만 1이고 나머지는 0인 형태를 __ont-hot-vector__ 라고 부르고 이렇게 변환시키는 과정을 __ont-hot-encoding__이라고 부른다.  \n",
    "정답을 이렇게 설정해주고 결과값은 소프트맥스 함수를 통해 확률로 바꿔준다. 수식은 다음과 같다. \n",
    "$$softmax(y_i) = \\frac{exp(y_i)}{\\sum_{j} exp(y_j)}$$   \n",
    "이를 통해 결과값은 확률 값으로 변환이 된다. 이제 손실을 측정해야하는데 클래스를 구분하는 작업에서는 앞에서 배운 L1Loss 함수보다 __Cross Entropy__ 함수를 주로 사용한다. 그 전에 엔트로피를 수식으로 먼저 살펴보면 다음과 같다.  \n",
    "$$H(p) = -\\sum_{x}p(x)\\log p(x)$$\n",
    "이 수식은 p(x)가 일어날 확률이 낮아 작은 값을 가질 때, -log p(x)의 값은 커지게 된다.  \n",
    "정리하면, 일어날 확률이 작을수록 가지고 있는 정보가 크고, 일어날 확률이 클수록 가지고 있는 정보가 작다는 것이다.  \n",
    "이 때, 분포의 차이에 의해 생기는 추가적 손실을 구해주기 위해 교차 엔트로피를 사용한다. 식은 다음과 같다.  \n",
    "$$H(p, q) = -\\sum_{x}p(x)\\log q(x)$$  \n",
    "교차 엔트로피는 목표로 하는 최적의 확률분포 p와 이를 근사하려는 확률분포 q가 얼마나 다른지를 측정하는 방법이다. 예를 들어 동전을 던지는 경우를 생각해보자.   \n",
    "이 경우 앞면이 나올 확률과 뒷면이 나올 확률은 각각 0.5로 같다. 그런데 누군가가 앞면이 나올 확률이 0.25, 뒷면이 나올 확률이 0.75라고 예측했다고 하자.  \n",
    "원래라면 엔트로피의 값이 1이 나와야 하지만 이 경우 $$H(p, q) = 0.5 * (-\\log_2 0.25) + 0.5 * (-\\log_2 0.75) = 1 + 0.2075 = 1.2075$$\n",
    "로 식이 계산된다.  \n",
    "식을 전개해서 다음과 같이 표현하기도 한다.  \n",
    "$$H(p, q) = H(p) + \\sum_{x}p(x)\\log \\frac{p(x)}{q(x)}   \n",
    "          = H(P) + D_{KL}(p||q) $$   \n",
    "여기서 KLD는 __쿨백-라이블러 발산(Kullback-Leibler divergence)__로, 분포 p를 기준으로 q가 얼마나 다른지를 측정하는 방법이다. 여기서 p의 엔트로피는 이미 정해진 고정값이므로 우리는 KLD를 최소화하여 p와 q의 분포가 최대한 같아지게 만든다.  \n",
    "교차 엔트로피의 장점은, 예측값이 잘못되었을 경우, L1Loss보다 손실값이 크다는 것이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "okNJ473WqfEl"
   },
   "source": [
    "# 모듈 불러오기 및 하이퍼파라미터 설정(필터 개수, 은닉층 개수, 학습률, 배치 사이즈 등) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "m95Jiqrmqrby"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 256\n",
    "learning_rate = 0.0002\n",
    "num_epoch = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aPS2L1KJrlqy"
   },
   "source": [
    "# 데이터 받아오기 \n",
    "## dset.MNIST\n",
    "- dset.MNIST 에서 첫번째 인수는 데이터의 경로이다. MNIST 데이터베이스에는 0부터 9까지를 손으로 쓴 이미지 데이터이다. \n",
    "- train이 True면 학습 데이터를, False면 테스트 데이터를 불러온다.  \n",
    "- transform과 target_transform은 각각 데이터와 라벨에 대한 변형을 의미한다. \n",
    "- download는 현재 경로에 MNIST 데이터가 없을 경우 다운로드 한다는 설정이다. \n",
    "\n",
    "## DataLoader \n",
    "- dset.MNIST를 통해 정리된 데이터를 batch_size 개수만큼 묶는다. \n",
    "- shffle 여부와 데이터를 묶을 때 사용할 프로세스의 개수(num_workers), 묶고 남는 데이터는 버릴지에 대한 여부(drop_last)를 인자로 받는다. \n",
    "- train_loader와 test_loader는 모델에 데이터를 전달해준다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "hUxp3HmUrqgm"
   },
   "outputs": [],
   "source": [
    "mnist_train = dset.MNIST(\"./\", train=True, transform=transforms.ToTensor(),\n",
    "                         target_transform=None, download=True)\n",
    "mnist_test = dset.MNIST(\"./\", train=False, transform=transforms.ToTensor(),\n",
    "                        target_transform=None, download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, \n",
    "                                           shuffle=True, num_workers=2, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAchCKddtqaS"
   },
   "source": [
    "# CNN 클래스 \n",
    "## nn.Conv2d \n",
    "- in_channels, out_channels: 말 그대로 입력값의 채널 수와 결과값의 채널 수를 설정하는 파라미터이다. \n",
    "- 예제에서 kernel_size는 5로 설정하였고, stride와 padding은 디폴트로 1과 0으로 설정된다. \n",
    "\n",
    "## nn.MaxPool2d  \n",
    "- kernel_size: 풀링 연산을 할 때 한 번에 훑는 영역의 크기. \n",
    "- stride와 padding 또한 인수로 받는다. \n",
    "\n",
    "self.layer 함수를 실행하고 나면 1x28x28 이었던 입력값은 64x3x3이 된다.  \n",
    "이후에 forward 함수에서 64x3x3의 데이터를 view 함수를 통해 batch_size x ? 의 크기로 reshape 해준다. 이렇게 형태가 바뀐 텐서에 nn.Linear(64x3x3, 100), nn.ReLU(), nn.Linear(100, 10)을 차례대로 실행하면 batch_size x 10 형태의 텐서가 나오게 된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "HwYioMfFugjK"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(CNN, self).__init__()\n",
    "    self.layer = nn.Sequential(\n",
    "        nn.Conv2d(1, 16, 5),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(16, 32, 5),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2, 2),\n",
    "        nn.Conv2d(32, 64, 5),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2, 2)\n",
    "    )\n",
    "    self.fc_layer = nn.Sequential(\n",
    "        nn.Linear(64*3*3, 100),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(100, 10)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = self.layer(x)\n",
    "    out = out.view(batch_size, -1)\n",
    "    out = self.fc_layer(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ono_CeJhy62i"
   },
   "source": [
    "# 손실 함수 지정 \n",
    "SGD 대신 Adam 알고리즘을 사용 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "i1rzQvsqzBYE"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN().to(device)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yNVyQTITzbQm"
   },
   "source": [
    "# 학습 진행 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UbtdextqzdVg",
    "outputId": "3e34fb9e-413e-422e-f0b9-6c085deab7e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0389, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0476, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0217, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0193, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0129, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0340, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0175, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0125, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0344, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "loss_arr = []\n",
    "for i in range(num_epoch):\n",
    "  for j, [image, label] in enumerate(train_loader):\n",
    "    x = image.to(device)\n",
    "    y_ = label.to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    output = model.forward(x)\n",
    "    loss = loss_func(output, y_)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if j % 1000 == 0:\n",
    "        print(loss)\n",
    "        loss_arr.append(loss.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "STqewFit0LPy"
   },
   "source": [
    "# 모델 검증 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hdIubgRa0N0J",
    "outputId": "9836a59e-d70f-4f2b-b1af-f1d7d586746c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Test Data: 99.13861846923828\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "  for image, label in test_loader:\n",
    "    x = image.to(device)\n",
    "    y_ = label.to(device)\n",
    "\n",
    "    output = model.forward(x)\n",
    "    _, output_index = torch.max(output, 1)\n",
    "\n",
    "    total += label.size(0)\n",
    "    correct += (output_index == y_).sum().float()\n",
    "\n",
    "  print(\"Accuracy of Test Data: {}\".format(100*correct/total))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPxLMcngT78vR0a3VCqnGTF",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
